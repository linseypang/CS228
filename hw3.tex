\def\s{\section*}
\def\ss{\subsection*}
\def\sp{\hspace{3 mm}}
\def\ind{\!\perp\!\!\!\perp}
\def\m{\mid}
\def\nl{ \\ = \sp &}
\newcommand{\eq}[1]{\begin{align*}&{#1}\end{align*}}
\renewcommand{\ss}[1]{\subsection*{#1}}
\renewcommand{\P}[1]{\s{Problem #1}}
\def\ra{\rightarrow}
\def\la{\leftarrow}
\def \pb{\newline\newline}
\newcommand{\pic}[2]{\begin{figure}[h!]
  \includegraphics[width=\linewidth]{#2}
  \caption{#1}
  \label{fig:net}
\end{figure}}

\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{parskip}
\usepackage{amsfonts}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{amssymb}
\author{Hugh Zhang}
\title{CS 228 Problem Set 1}
\date{\today}
\begin{document}
\maketitle

\P 1

Let the structure be a two node binary Bayes net with one edge from A to B. Let $P(A=1) = 0.51, P(B=1 \mid A=1) = .5, P(B=1 \mid A=0) = .99$

Then, $P(B=1) = 0.51*.5 + 0.49*.99 = .7401$, so the most likely outcome based on marginals without looking at conditionals is $A=1, B=1$. However, the $P(A=1,B=1) = .51*.5 = .255$. This is not as likely as the most likely outcome, A=0,B=1 which has $P(A=0,B=1) = .49*.99 = .4851$.

\P 2

Basic message passing is $nd^2$ for a chain. Labeling the nodes from A to Y WLOG, you can factor
\[
P(A\dots Y) = \phi(A,B) * \phi(B,C) \dots \phi(X,Y)
\]
Z, which is the normalizing constant is just
\begin{align*}
& \sum_A\dots\sum_Y P(A\dots Y) = \sum_A\sum_B\phi(A,B) * \sum_C\phi(B,C) \dots \sum_Y\phi(X,Y)
\end{align*}
Z takes $nd^2$ time to calculate because each minisum function takes d time to evaluate per  EXPLAIN THIS PLEASE. EACH FUNCTION IS D time, and D evaluations per update


\ss{2.2}

Note that $X_i$ and $X_j$ are independent conditioned on $X_{j-1}$
\[P(X_i,X_j)=\sum_{x_{j-1}} P(X_i,X_{j-1})P(X_j \mid X_{j-1})\]

\P 3

If you change a factor (by changing its value, or by adding an edge) in a clique, check all its neighbors and see if they are affected, AKA the seperation set contains the factor that has been changed. If they are affected, then everything in that entire subtree needs to be updated, since they all depend on that factor in the message passing.

\ss{3.2}

If you only want the marginal over a single variable, you only need to pass the message along the single path to the variable you want to calculate. In addition, you don't need to update the entire tree, just for every node that you are d-seperated on since you marginalize the probability out otherwise.

EQUATION FOR MESSAGE DOESN"T DEPEND ON THE OLD GUY. Calibrated only if all the messages that are coming in are ok.

\P 4

\ss{4.2.1}

Inference is exponential. 
No

Yes, forward prop

\end{document}
